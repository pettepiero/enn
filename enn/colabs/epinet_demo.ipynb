{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KneoLFE258NW"
      },
      "source": [
        "# Run a pre-trained Epinet on ImageNet\n",
        "This demo shows how to run and evaluate a pre-trained *Epinet* on ImageNet. Epinet is a new ENN architecture that can supplement any conventional NN and be trained to estimate uncertainty.\n",
        "\n",
        "\n",
        "An epinet is a neural network with privileged access to inputs and outputs of activation units in the base network.\n",
        "A subset of these inputs and outputs, denoted by $\\phi_\\zeta(x)$, are taken as input to the epinet along with an epistemic index $z$.\n",
        "For epinet parameters $\\eta$, the epinet outputs $\\sigma_\\eta(\\phi_\\zeta(x), z)$.\n",
        "To produce an ENN, the output of the epinet is added to that of the base network, though with a \"stop gradient\" written $[[\\cdot]]$:\n",
        "\n",
        "$$ f_\\theta(x, z) = \\mu_\\zeta(x) + \\sigma_\\eta([[\\phi_\\zeta(x)]], z). $$\n",
        "\n",
        "\n",
        "We can visualize this network architecture:\n",
        "\n",
        "![epinet diagram](https://raw.githubusercontent.com/deepmind/enn/master/statics/images/epinet_new.png)\n",
        "\n",
        "For more details about Epinet, refer to the paper \n",
        "[Epistemic Neural Networks](https://arxiv.org/abs/2107.08924) (Osband et al., 2022).\n",
        "\n",
        "It's recommended to use `Runtime->Change Runtime Type` to pick a GPU for speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGU1LEXZsplN",
        "outputId": "1e89c400-d08a-429c-ee1a-ad3e1a957134"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'enn (Python 3.10.14)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/home/pettepiero/Downloads/venvs/enn/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Copyright 2022 DeepMind Technologies Limited. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "# !git clone https://github.com/deepmind/enn.git\n",
        "# !pip install -q enn/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV8NEOiudvoZ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "qXOubWdlH9C0",
        "outputId": "d949eef3-68ca-48b2-8c4d-dd85da97e508"
      },
      "outputs": [],
      "source": [
        "#@title General imports\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "#@title Development imports\n",
        "from typing import Callable, NamedTuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotnine as gg\n",
        "\n",
        "import dataclasses\n",
        "import chex\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "import dill\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "EoyK1tD9Vjvo"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'enn.checkpoints.base' has no attribute 'EnnCheckpoint' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m checkpoint_base\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mepinet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m epinet_base\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
            "File \u001b[0;32m~/Downloads/venvs/enn/lib/python3.10/site-packages/enn/checkpoints/base.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Optional, Tuple\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhaiku\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhk\u001b[39;00m\n\u001b[1;32m     25\u001b[0m EnnCtor \u001b[38;5;241m=\u001b[39m Callable[[], base\u001b[38;5;241m.\u001b[39mEnnArray]\n",
            "File \u001b[0;32m~/Downloads/venvs/enn/lib/python3.10/site-packages/enn/networks/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-file-header\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2021 DeepMind Technologies Limited. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"Exposing the public methods of the networks.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m epinet\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Base\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ApplyArray\n",
            "File \u001b[0;32m~/Downloads/venvs/enn/lib/python3.10/site-packages/enn/networks/epinet/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"Public methods for epinet.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Base\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mepinet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseHiddenParser\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mepinet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combine_base_epinet_as_enn\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01menn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetworks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mepinet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EpinetApplyWithState\n",
            "File \u001b[0;32m~/Downloads/venvs/enn/lib/python3.10/site-packages/enn/networks/epinet/base.py:69\u001b[0m\n\u001b[1;32m     62\u001b[0m   indexer: base\u001b[38;5;241m.\u001b[39mEpistemicIndexer\n\u001b[1;32m     65\u001b[0m BaseHiddenParser \u001b[38;5;241m=\u001b[39m Callable[[networks_base\u001b[38;5;241m.\u001b[39mOutput], chex\u001b[38;5;241m.\u001b[39mArray]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_base_epinet_as_enn\u001b[39m(\n\u001b[0;32m---> 69\u001b[0m     base_checkpoint: \u001b[43mcheckpoint_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEnnCheckpoint\u001b[49m,\n\u001b[1;32m     70\u001b[0m     epinet: EpinetWithState,\n\u001b[1;32m     71\u001b[0m     parse_hidden: BaseHiddenParser,\n\u001b[1;32m     72\u001b[0m     base_index: Optional[base\u001b[38;5;241m.\u001b[39mIndex] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     73\u001b[0m     base_scale: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     74\u001b[0m     freeze_base: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m networks_base\u001b[38;5;241m.\u001b[39mEnnArray:\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a combined ENN from a base network and an epinet.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m      combined with those of the base network. Useful for finetuning.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m   \u001b[38;5;66;03m# TODO(author2): Add testing to this function.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m   \u001b[38;5;66;03m# Parse the base network from checkpoint\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'enn.checkpoints.base' has no attribute 'EnnCheckpoint' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "#@title ENN imports\n",
        "import enn\n",
        "from enn import datasets\n",
        "from enn.checkpoints import base as checkpoint_base\n",
        "from enn.networks.epinet import base as epinet_base\n",
        "from enn.checkpoints import utils\n",
        "from enn.checkpoints import imagenet\n",
        "from enn.checkpoints import catalog\n",
        "from enn.loggers import TerminalLogger\n",
        "from enn import metrics as enn_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbswxUJc8fuA"
      },
      "source": [
        "## Load ImageNet dataset\n",
        "\n",
        "Our `enn` library provides functionalities in `enn/datasets` to load ImageNet, CIFAR10/100, and MNIST datasets. To load these datasets, you need to download that dataset into the default tensorflow dataset directory of `~/tensorflow_datasets/downloads/manual/`. \n",
        "\n",
        "In this colab, we want to evaluate Epinet on only one small batch of ImageNet test images. To this end, we provide a sample batch of size 100 at [https://storage.googleapis.com/dm-enn/processed_batch.npzs](https://storage.googleapis.com/dm-enn/processed_batch.npzs) which can be download as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w5B1HVEto-P",
        "outputId": "d9b402b4-c03b-466c-b06b-50d87398d030"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.googleapis.com/dm-enn/processed_batch.npzs --no-check-certificate\n",
        "with open('processed_batch.npzs', 'rb') as file:\n",
        "  batch = dill.load(file)\n",
        "images, labels = batch['images'], batch['labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi3IzBqoSGkK"
      },
      "source": [
        "## Define a set of evaluation metrics\n",
        "\n",
        "Our `enn` library provides the set of known metrics for evaluating the performance of neural networks. These metrics which can be access from `enn/metrics` can be divided in three categories:\n",
        "\n",
        "\n",
        "1.   **Marginal**: includes metrics like accuracy and marginal negative log-likelihood (NLL) for evaluating marginal predictions.\n",
        "2.   **Joint**: includes metrics for evaluating joint predictions. \n",
        "3.   **Calibration**: includes metrics for calculating calibration error.\n",
        "\n",
        "Each metric takes logits and labels with the following shapes:\n",
        "  - logits: [num_enn_samples, batch_size, num_classes]\n",
        "  - labels: [batch_size, 1]\n",
        "\n",
        "`num_enn_samples` specifies the number of sample logits per input image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaoht3UJJb2m"
      },
      "outputs": [],
      "source": [
        "# Define a dict of metrics including `accuracy`, `marginal nll`, and `joint nll`.\n",
        "evaluation_metrics = {\n",
        "      'accuracy': enn_metrics.make_accuracy_calculator(),\n",
        "      'marginal nll': enn_metrics.make_nll_marginal_calculator(),\n",
        "      'joint nll': enn_metrics.make_nll_polyadic_calculator(tau=10, kappa=2),\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB26yDlmHxvj"
      },
      "source": [
        "## Load pre-trained Epinet\n",
        "\n",
        "Pre-trained Epinet can be accessed from `ImagenetModels` in `enn.checkpointing.catalog.py`. As of now, we provide pre-trained Epinet based on ResNet-50, ResNet-101, ResNet-152, and ResNet-200. In this colab, we want to load Epinet based on ResNet-50 which can be accessed from the checkpoint `RESNET_50_FINAL_EPINET`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMA2Stmjm_6O",
        "outputId": "67f14393-45e5-4b4c-dfcc-6757a56e5b50"
      },
      "outputs": [],
      "source": [
        "# Get the Epinet checkpoint\n",
        "epinet_resnet50_imagenet_ckpt = catalog.ImagenetModels.RESNET_50_FINAL_EPINET.value\n",
        "epinet_resnet50_imagenet_ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0B8ytqQJFAN"
      },
      "source": [
        "From the checkpoint, we can recover an enn sampler, which is a function that takes a batch of images and one random key, and returns multiple sample logits per input image. To recover the enn sampler, we can use `make_epinet_sampler_from_checkpoint` (from `enn/checkpoints/utils.py`) which takes the checkpoint and also the number of sample logits we want per image (`num_enn_samples`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCcrOudvI_t_"
      },
      "outputs": [],
      "source": [
        "# Set the number of sample logits per input image\n",
        "num_enn_samples = 100\n",
        "# Recover the enn sampler\n",
        "epinet_enn_sampler = utils.make_epinet_sampler_from_checkpoint(\n",
        "    epinet_resnet50_imagenet_ckpt,\n",
        "    num_enn_samples=num_enn_samples,)\n",
        "# Get the epinet logits\n",
        "key = jax.random.PRNGKey(seed=0)\n",
        "epinet_logits = epinet_enn_sampler(images, key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67UZuK97Ri-W",
        "outputId": "2e18a730-ec8b-491a-a4d3-15cca0bac3f9"
      },
      "outputs": [],
      "source": [
        "# epinet logits has shape [num_enn_sample, eval_batch_size, num_classes]\n",
        "epinet_logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja9bC0Q7UVkM",
        "outputId": "6b91764d-71c1-40dd-fcd7-89ad4d3d27cb"
      },
      "outputs": [],
      "source": [
        "# Labels loaded from our dataset has shape [eval_batch_size,]. Our evaluation\n",
        "# metrics requires labels to have shape [eval_batch_size, 1].\n",
        "eval_labels = labels[:, None]\n",
        "# Evaluate \n",
        "epinet_results = {key: float(metric(epinet_logits, eval_labels)) \n",
        "                      for key, metric in evaluation_metrics.items()}\n",
        "epinet_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnY-iLAkW_u4"
      },
      "source": [
        "## Load pre-trained ResNet\n",
        "\n",
        "To have a better sense of how amazing Epinet is, we can compare its performance with a pretrained ResNet-50.\n",
        "\n",
        "Pre-trained ResNets can be accessed from `ImagenetModels` in `enn.checkpointing.catalog.py`. As of now, we provide pre-trained ResNet-50, ResNet-101, ResNet-152, and ResNet-200. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocO9OQv4HIxn",
        "outputId": "b0c37332-fb7d-42bc-a395-0bf35c3a94a3"
      },
      "outputs": [],
      "source": [
        "# Get the ResNet-50 checkpoint\n",
        "resnet50_imagenet_ckpt = catalog.ImagenetModels.RESNET_50.value\n",
        "resnet50_imagenet_ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sSq3q9ZXzy-"
      },
      "source": [
        "From the checkpoint, we can recover an enn sampler, which is a function that takes a batch of images and one random key, and returns multiple sample logits per input image. To recover the enn sampler for ResNet-50, we can use `make_enn_sampler_from_checkpoint` (from `enn/checkpoints/utils.py`) which takes the checkpoint and also the number of sample logits we want per image (`num_enn_samples`). Here we set `num_enn_samples=1`, as having `num_enn_samples > 1` just results in multiple similar sample logits per input image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NixEickNXzFE"
      },
      "outputs": [],
      "source": [
        "# Set the number of sample logits per input image to 1\n",
        "num_enn_samples = 1\n",
        "# Recover the enn sampler\n",
        "resnet50_enn_sampler = utils.make_enn_sampler_from_checkpoint(\n",
        "    resnet50_imagenet_ckpt,\n",
        "    num_enn_samples=num_enn_samples,)\n",
        "# Get the epinet logits\n",
        "key = jax.random.PRNGKey(seed=0)\n",
        "resnet50_logits = resnet50_enn_sampler(images, key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PNNqG4aY2cl",
        "outputId": "bb980423-ae4e-4932-c180-d317a86aff65"
      },
      "outputs": [],
      "source": [
        "# ResNet logits has shape [num_enn_sample, eval_batch_size, num_classes]\n",
        "resnet50_logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUb2u94_Y90P",
        "outputId": "dcf98ebe-81db-4d23-a01f-541619a03ba5"
      },
      "outputs": [],
      "source": [
        "# Labels loaded from our dataset has shape [eval_batch_size,]. Our evaluation\n",
        "# metrics requires labels to have shape [eval_batch_size, 1].\n",
        "eval_labels = labels[:, None]\n",
        "# Evaluate \n",
        "resnet50_results = {key: float(metric(resnet50_logits, eval_labels)) \n",
        "                      for key, metric in evaluation_metrics.items()}\n",
        "resnet50_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFhzjoYCawiY"
      },
      "source": [
        "## Compare Epinet and ResNet results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 112
        },
        "id": "gMvIsE4aa3Ex",
        "outputId": "6d92fce0-22bc-49ec-87f6-21833d575068"
      },
      "outputs": [],
      "source": [
        "# Make a dataframe of the results\n",
        "resnet50_results['model'] = 'resnet'\n",
        "epinet_results['model'] = 'epinet'\n",
        "df = pd.DataFrame([resnet50_results, epinet_results])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 422
        },
        "id": "kucVaz3Ya9h6",
        "outputId": "a68bf94b-46e5-4f8c-d4b8-0e4ae991dc54"
      },
      "outputs": [],
      "source": [
        "# Compare the results\n",
        "plt_df = pd.melt(df, id_vars=['model'], value_vars=evaluation_metrics.keys())\n",
        "p = (gg.ggplot(plt_df)\n",
        "    + gg.aes(x='model', y='value', fill='model') \n",
        "    + gg.geom_col()\n",
        "    + gg.facet_wrap('variable', scales='free',)\n",
        "    + gg.theme(figure_size=(14, 4), panel_spacing=0.7)\n",
        "    )\n",
        "p"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "epinet_demo.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
